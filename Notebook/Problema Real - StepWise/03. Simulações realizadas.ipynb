{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes/funções auxiliares\n",
    "from numpy import linspace\n",
    "\n",
    "# Técnicas de random sampling utilizadas\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks, EditedNearestNeighbours\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Algoritmos de Machine Learning clássicos\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Algoritmos de Machine Learning modificados para lidar com dados desbalanceados\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from imbens.ensemble import OverBoostClassifier, SMOTEBoostClassifier, OverBaggingClassifier, SMOTEBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização dos Modelos a serem utilizados nessa análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tecnicas_de_random_sampling = {\n",
    "    'RandomUnderSampler': RandomUnderSampler(),\n",
    "    'RandomOverSampler': RandomOverSampler(),\n",
    "    'NearMiss-1': NearMiss(version = 1),\n",
    "    'NearMiss-2': NearMiss(version = 2),\n",
    "    'NearMiss-3': NearMiss(version = 3),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "    'ENN' : EditedNearestNeighbours(),\n",
    "    'ADASYN' : ADASYN(),\n",
    "    'SMOTE' : SMOTE(),\n",
    "    'BorderlineSMOTE-1' : BorderlineSMOTE(kind = 'borderline-1'),\n",
    "    'BorderlineSMOTE-2' : BorderlineSMOTE(kind= 'borderline-2'),\n",
    "    'SMOTEEN' : SMOTEENN(),\n",
    "    'SMOTETomek' : SMOTETomek()\n",
    "}\n",
    "\n",
    "\n",
    "algoritmos_classicos = {\n",
    "    'DecisionTree' : DecisionTreeClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'Bagging' : BaggingClassifier(),\n",
    "    'RandomForest' : RandomForestClassifier(),\n",
    "    'XGBoost' : XGBClassifier(),\n",
    "    'LogisticRegression' : LogisticRegression(penalty = None)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "algoritmos_desafiantes = {\n",
    "    'EasyEnsemble' : EasyEnsembleClassifier(),\n",
    "    'BalancedBaggingClassifier' : BalancedBaggingClassifier(),\n",
    "    'BalancedRandomForestClassifier' : BalancedRandomForestClassifier(),\n",
    "    'RUSBoost' : RUSBoostClassifier(),\n",
    "    'OverBoost' : OverBoostClassifier(),\n",
    "    'SMOTEBoost' : SMOTEBoostClassifier(),\n",
    "    'OverBagging' : OverBaggingClassifier(),\n",
    "    'SMOTEBagging' : SMOTEBaggingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaboração da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[553, 842, False, ..., False, True, False],\n",
       "       [783, 142, False, ..., False, True, False],\n",
       "       [647, 647, False, ..., False, True, False],\n",
       "       ...,\n",
       "       [528, 343, False, ..., False, False, False],\n",
       "       [314, 567, False, ..., False, True, False],\n",
       "       [446, 126, True, ..., False, False, True]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"H:\\Meu Drive\\Dissertacao\\Bases\\StepWise Aplication Data (Modelagem).csv\")\n",
    "\n",
    "df.drop(['data', 'amostra'], axis = 1, inplace = True)\n",
    "# Selecionar 2000 instâncias com inadimplência igual a 1\n",
    "\n",
    "X, y = df.drop('inadimplencia', axis = 1), df['inadimplencia']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "\n",
    "# Tratar o nome das colunas de X_dummies\n",
    "X.columns = X.columns.str.lower().str.replace('[^\\w\\s]', '').str.replace(' ', '_')\n",
    "\n",
    "X = X.to_numpy()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação - Algoritmos Clássicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Função para calcular a métrica KS\n",
    "def ks_metric(y_true, y_pred_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    return max(tpr - fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree com DecisionTreeClassifier()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m metrics_list \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Initialize metrics_list for each model\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(\u001b[43mX\u001b[49m, y), \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Obter os conjuntos de treinamento e teste para o fold atual\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m X[train_index], X[test_index]\n\u001b[0;32m     29\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# DataFrame para armazenar as métricas\n",
    "metrics_df = pd.DataFrame(columns=['Algoritmo', 'Precisão', 'Recall', 'F1-Score', 'ROC AUC', 'KS'])\n",
    "\n",
    "# Loop através dos algoritmos clássicos\n",
    "for name, model in algoritmos_classicos.items():\n",
    "    \n",
    "    print(f'{name} com {model}')\n",
    "    \n",
    "    # Configuração da validação cruzada\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "    \n",
    "    metrics_list = []  # Initialize metrics_list for each model\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(cv.split(X, y), 1):\n",
    "        # Obter os conjuntos de treinamento e teste para o fold atual\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        # Otimizar o ponto de corte\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "        # Calcular métricas\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        ks = ks_metric(y_test, y_pred_proba)\n",
    "\n",
    "        metrics_list.append({\n",
    "            'Precisão': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'KS': ks\n",
    "        })\n",
    "\n",
    "    # Calcular a média das métricas\n",
    "    avg_metrics = {\n",
    "        'Precisão': np.mean([m['Precisão'] for m in metrics_list]),\n",
    "        'Recall': np.mean([m['Recall'] for m in metrics_list]),\n",
    "        'F1-Score': np.mean([m['F1-Score'] for m in metrics_list]),\n",
    "        'ROC AUC': np.mean([m['ROC AUC'] for m in metrics_list]),\n",
    "        'KS': np.mean([m['KS'] for m in metrics_list])\n",
    "    }\n",
    "    \n",
    "    avg_metrics['Algoritmo'] = name  # Add algorithm name to avg_metrics\n",
    "    \n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame([avg_metrics])], ignore_index=True)\n",
    "        \n",
    "metrics_df.sort_values(['F1-Score', 'ROC AUC', 'KS'], ascending=False).to_csv(r'H:\\Meu Drive\\Dissertacao\\Notebook\\Problema Real - StepWise\\Resultados\\algoritmos_classicos.csv', index=False)\n",
    "\n",
    "metrics_df.sort_values(['F1-Score', 'ROC AUC', 'KS'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.sort_values('ROC AUC', ascending = False).to_clipboard(index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação - Algoritmos Clássicos com Técnicas de Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree com RandomUnderSampler\n",
      "AdaBoost com RandomUnderSampler\n",
      "Bagging com RandomUnderSampler\n",
      "RandomForest com RandomUnderSampler\n",
      "XGBoost com RandomUnderSampler\n",
      "LogisticRegression com RandomUnderSampler\n",
      "DecisionTree com RandomOverSampler\n",
      "AdaBoost com RandomOverSampler\n",
      "Bagging com RandomOverSampler\n",
      "RandomForest com RandomOverSampler\n",
      "XGBoost com RandomOverSampler\n",
      "LogisticRegression com RandomOverSampler\n",
      "DecisionTree com NearMiss-1\n",
      "AdaBoost com NearMiss-1\n",
      "Bagging com NearMiss-1\n",
      "RandomForest com NearMiss-1\n",
      "XGBoost com NearMiss-1\n",
      "LogisticRegression com NearMiss-1\n",
      "DecisionTree com NearMiss-2\n",
      "AdaBoost com NearMiss-2\n",
      "Bagging com NearMiss-2\n",
      "RandomForest com NearMiss-2\n",
      "XGBoost com NearMiss-2\n",
      "LogisticRegression com NearMiss-2\n",
      "DecisionTree com NearMiss-3\n",
      "AdaBoost com NearMiss-3\n",
      "Bagging com NearMiss-3\n",
      "RandomForest com NearMiss-3\n",
      "XGBoost com NearMiss-3\n",
      "LogisticRegression com NearMiss-3\n",
      "DecisionTree com TomekLinks\n",
      "AdaBoost com TomekLinks\n",
      "Bagging com TomekLinks\n",
      "RandomForest com TomekLinks\n",
      "XGBoost com TomekLinks\n",
      "LogisticRegression com TomekLinks\n",
      "DecisionTree com ENN\n",
      "AdaBoost com ENN\n",
      "Bagging com ENN\n",
      "RandomForest com ENN\n",
      "XGBoost com ENN\n",
      "LogisticRegression com ENN\n",
      "DecisionTree com ADASYN\n",
      "AdaBoost com ADASYN\n",
      "Bagging com ADASYN\n",
      "RandomForest com ADASYN\n",
      "XGBoost com ADASYN\n",
      "LogisticRegression com ADASYN\n",
      "DecisionTree com SMOTE\n",
      "AdaBoost com SMOTE\n",
      "Bagging com SMOTE\n",
      "RandomForest com SMOTE\n",
      "XGBoost com SMOTE\n",
      "LogisticRegression com SMOTE\n",
      "DecisionTree com BorderlineSMOTE-1\n",
      "AdaBoost com BorderlineSMOTE-1\n",
      "Bagging com BorderlineSMOTE-1\n",
      "RandomForest com BorderlineSMOTE-1\n",
      "XGBoost com BorderlineSMOTE-1\n",
      "LogisticRegression com BorderlineSMOTE-1\n",
      "DecisionTree com BorderlineSMOTE-2\n",
      "AdaBoost com BorderlineSMOTE-2\n",
      "Bagging com BorderlineSMOTE-2\n",
      "RandomForest com BorderlineSMOTE-2\n",
      "XGBoost com BorderlineSMOTE-2\n",
      "LogisticRegression com BorderlineSMOTE-2\n",
      "DecisionTree com SMOTEEN\n",
      "AdaBoost com SMOTEEN\n",
      "Bagging com SMOTEEN\n",
      "RandomForest com SMOTEEN\n",
      "XGBoost com SMOTEEN\n",
      "LogisticRegression com SMOTEEN\n",
      "DecisionTree com SMOTETomek\n",
      "AdaBoost com SMOTETomek\n",
      "Bagging com SMOTETomek\n",
      "RandomForest com SMOTETomek\n",
      "XGBoost com SMOTETomek\n",
      "LogisticRegression com SMOTETomek\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>Técnica de Sampling</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>BorderlineSMOTE-2</td>\n",
       "      <td>0.099122</td>\n",
       "      <td>0.576136</td>\n",
       "      <td>0.165261</td>\n",
       "      <td>0.669650</td>\n",
       "      <td>0.272995</td>\n",
       "      <td>0.252205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTEEN</td>\n",
       "      <td>0.094618</td>\n",
       "      <td>0.594906</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.683246</td>\n",
       "      <td>0.290201</td>\n",
       "      <td>0.750735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.095357</td>\n",
       "      <td>0.556515</td>\n",
       "      <td>0.161839</td>\n",
       "      <td>0.668787</td>\n",
       "      <td>0.269542</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>0.094265</td>\n",
       "      <td>0.563061</td>\n",
       "      <td>0.160930</td>\n",
       "      <td>0.673713</td>\n",
       "      <td>0.273770</td>\n",
       "      <td>0.750735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.094759</td>\n",
       "      <td>0.566383</td>\n",
       "      <td>0.160719</td>\n",
       "      <td>0.670985</td>\n",
       "      <td>0.268342</td>\n",
       "      <td>0.651029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NearMiss-1</td>\n",
       "      <td>0.050458</td>\n",
       "      <td>0.994507</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.407860</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.501470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NearMiss-1</td>\n",
       "      <td>0.059820</td>\n",
       "      <td>0.669953</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>0.429962</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NearMiss-1</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.481381</td>\n",
       "      <td>0.074405</td>\n",
       "      <td>0.446113</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>NearMiss-1</td>\n",
       "      <td>0.145095</td>\n",
       "      <td>0.654609</td>\n",
       "      <td>0.066786</td>\n",
       "      <td>0.410895</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>NearMiss-1</td>\n",
       "      <td>0.033642</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.442289</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.900294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algoritmo Técnica de Sampling  Precisão    Recall  F1-Score  \\\n",
       "62        RandomForest   BorderlineSMOTE-2  0.099122  0.576136  0.165261   \n",
       "68        RandomForest             SMOTEEN  0.094618  0.594906  0.162883   \n",
       "44        RandomForest              ADASYN  0.095357  0.556515  0.161839   \n",
       "74        RandomForest          SMOTETomek  0.094265  0.563061  0.160930   \n",
       "50        RandomForest               SMOTE  0.094759  0.566383  0.160719   \n",
       "..                 ...                 ...       ...       ...       ...   \n",
       "14        RandomForest          NearMiss-1  0.050458  0.994507  0.096043   \n",
       "16  LogisticRegression          NearMiss-1  0.059820  0.669953  0.089290   \n",
       "15             XGBoost          NearMiss-1  0.073497  0.481381  0.074405   \n",
       "12            AdaBoost          NearMiss-1  0.145095  0.654609  0.066786   \n",
       "13             Bagging          NearMiss-1  0.033642  0.646930  0.063957   \n",
       "\n",
       "     ROC AUC        KS  Imbalance Ratio  \n",
       "62  0.669650  0.272995         0.252205  \n",
       "68  0.683246  0.290201         0.750735  \n",
       "44  0.668787  0.269542         1.000000  \n",
       "74  0.673713  0.273770         0.750735  \n",
       "50  0.670985  0.268342         0.651029  \n",
       "..       ...       ...              ...  \n",
       "14  0.407860  0.006445         0.501470  \n",
       "16  0.429962  0.016962         1.000000  \n",
       "15  0.446113  0.011806         1.000000  \n",
       "12  0.410895  0.011470         1.000000  \n",
       "13  0.442289  0.003617         0.900294  \n",
       "\n",
       "[77 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame para armazenar as métricas\n",
    "metrics_sampling_df = pd.DataFrame(columns=['Algoritmo', 'Técnica de Sampling', 'Precisão', 'Recall', 'F1-Score', 'ROC AUC', 'KS'])\n",
    "\n",
    "# Loop através dos algoritmos clássicos e técnicas de random sampling\n",
    "# Obter a proporção de classes desbalanceadas\n",
    "ratio = sum(y == 1) / sum(y == 0)\n",
    "imbalance_ratio = linspace(1, ratio, 20)[:-1]\n",
    "\n",
    "# Configuração da validação cruzada\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "# Loop pelos folds para capturar os conjuntos de treinamento e teste\n",
    "# Loop através dos algoritmos clássicos e técnicas de random sampling\n",
    "for sampling_name, sampling_technique in tecnicas_de_random_sampling.items():\n",
    "    for model_name, model in algoritmos_classicos.items():\n",
    "        \n",
    "        print(f'{model_name} com {sampling_name}')\n",
    "        \n",
    "        best_f1 = 0\n",
    "        best_metrics = None\n",
    "        \n",
    "        # Variar a estratégia de sampling\n",
    "        for strategy in imbalance_ratio:\n",
    "            metrics_list = []\n",
    "\n",
    "            for fold, (train_index, test_index) in enumerate(cv.split(X, y), 1):\n",
    "                # Obter os conjuntos de treinamento e teste para o fold atual\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "                # Aplicar a técnica de random sampling\n",
    "                X_resampled, y_resampled = sampling_technique.fit_resample(X_train, y_train)\n",
    "\n",
    "                model.fit(X_resampled, y_resampled)\n",
    "\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "                # Otimizar o ponto de corte\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "                optimal_idx = np.argmax(tpr - fpr)\n",
    "                optimal_threshold = thresholds[optimal_idx]\n",
    "                y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "                # Calcular métricas\n",
    "                precision = precision_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "                ks = ks_metric(y_test, y_pred_proba)\n",
    "\n",
    "                metrics_list.append({\n",
    "                    'Precisão': precision,\n",
    "                    'Recall': recall,\n",
    "                    'F1-Score': f1,\n",
    "                    'ROC AUC': roc_auc,\n",
    "                    'KS': ks\n",
    "                })\n",
    "\n",
    "            # Calcular a média das métricas\n",
    "            avg_metrics = {\n",
    "                'Precisão': np.mean([m['Precisão'] for m in metrics_list]),\n",
    "                'Recall': np.mean([m['Recall'] for m in metrics_list]),\n",
    "                'F1-Score': np.mean([m['F1-Score'] for m in metrics_list]),\n",
    "                'ROC AUC': np.mean([m['ROC AUC'] for m in metrics_list]),\n",
    "                'KS': np.mean([m['KS'] for m in metrics_list])\n",
    "            }\n",
    "\n",
    "            if avg_metrics['F1-Score'] > best_f1:\n",
    "                best_f1 = avg_metrics['F1-Score']\n",
    "                best_metrics = {\n",
    "                    'Algoritmo': model_name,\n",
    "                    'Técnica de Sampling': sampling_name,\n",
    "                    'Precisão': avg_metrics['Precisão'],\n",
    "                    'Recall': avg_metrics['Recall'],\n",
    "                    'F1-Score': avg_metrics['F1-Score'],\n",
    "                    'ROC AUC': avg_metrics['ROC AUC'],\n",
    "                    'KS': avg_metrics['KS'],\n",
    "                    'Imbalance Ratio': strategy\n",
    "                }\n",
    "\n",
    "        # Adicionar as melhores métricas ao DataFrame\n",
    "        if best_metrics:\n",
    "            metrics_sampling_df = pd.concat([metrics_sampling_df, pd.DataFrame([best_metrics])], ignore_index=True)\n",
    "            # Salvar o DataFrame em um arquivo CSV\n",
    "            metrics_sampling_df.to_csv(r'H:\\Meu Drive\\Dissertacao\\Notebook\\Problema Real - StepWise\\Resultados\\metrics_sampling.csv', index=False)\n",
    "\n",
    "# Exibir o DataFrame com as métricas\n",
    "metrics_sampling_df.sort_values(['F1-Score', 'ROC AUC', 'KS'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "metrics_sampling_df.sort_values('F1-Score', ascending = False)[:10].to_clipboard(index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação - Extensões de Técnicas Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame para armazenar as métricas\n",
    "metrics_desafiantes_df = pd.DataFrame(columns=['Algoritmo', 'Precisão', 'Recall', 'F1-Score', 'ROC AUC', 'KS'])\n",
    "\n",
    "# Loop através dos algoritmos clássicos\n",
    "for name, model in algoritmos_desafiantes.items():\n",
    "    \n",
    "    # Configuração da validação cruzada\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "    \n",
    "    metrics_list = []  # Initialize metrics_list for each model\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(cv.split(X, y), 1):\n",
    "        # Obter os conjuntos de treinamento e teste para o fold atual\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        # Otimizar o ponto de corte\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "        # Calcular métricas\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        ks = ks_metric(y_test, y_pred_proba)\n",
    "\n",
    "        metrics_list.append({\n",
    "            'Precisão': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'ROC AUC': roc_auc,\n",
    "            'KS': ks\n",
    "        })\n",
    "\n",
    "    # Calcular a média das métricas\n",
    "    avg_metrics = {\n",
    "        'Precisão': np.mean([m['Precisão'] for m in metrics_list]),\n",
    "        'Recall': np.mean([m['Recall'] for m in metrics_list]),\n",
    "        'F1-Score': np.mean([m['F1-Score'] for m in metrics_list]),\n",
    "        'ROC AUC': np.mean([m['ROC AUC'] for m in metrics_list]),\n",
    "        'KS': np.mean([m['KS'] for m in metrics_list])\n",
    "    }\n",
    "    \n",
    "    avg_metrics['Algoritmo'] = name  # Add algorithm name to avg_metrics\n",
    "    \n",
    "    metrics_desafiantes_df = pd.concat([metrics_desafiantes_df, pd.DataFrame([avg_metrics])], ignore_index=True)\n",
    "        \n",
    "    metrics_desafiantes_df.sort_values(['F1-Score', 'ROC AUC', 'KS'], ascending=False)\n",
    "\n",
    "    metrics_desafiantes_df.to_csv(r'H:\\Meu Drive\\Dissertacao\\Notebook\\Problema Real - StepWise\\Resultados\\metrics_extensao_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "metrics_desafiantes_df.sort_values('F1-Score', ascending = False).to_clipboard(index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
