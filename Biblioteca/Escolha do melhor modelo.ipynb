{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Criar uma base de dados de classificação\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=2, n_redundant=10, n_classes=2, weights=[0.99, 0.01], random_state=42)\n",
    "\n",
    "# Converter para DataFrame para melhor visualização\n",
    "df_classification = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])\n",
    "df_classification['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, AdaBoostClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Definir diferentes valores de imbalance_ratio para testar, removendo o último elemento\u001b[39;00m\n\u001b[0;32m      8\u001b[0m imbalance_ratios \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m(np\u001b[38;5;241m.\u001b[39mbincount(y) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)), \u001b[38;5;241m20\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Definir diferentes valores de imbalance_ratio para testar, removendo o último elemento\n",
    "imbalance_ratios = np.linspace(1, min(np.bincount(y) / len(y)), 20)[:-1]\n",
    "\n",
    "# Lista para armazenar os f1-scores\n",
    "f1_scores = []\n",
    "\n",
    "# Loop para testar diferentes valores de imbalance_ratio\n",
    "# Lista de modelos para treinar\n",
    "# Definir os hiperparâmetros para otimização bayesiana\n",
    "param_grid = {\n",
    "    'DecisionTree': {\n",
    "        'max_depth': (1, 20),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 20)\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': (10, 200),\n",
    "        'max_depth': (1, 20),\n",
    "        'min_samples_split': (2, 20),\n",
    "        'min_samples_leaf': (1, 20)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': (10, 200),\n",
    "        'max_depth': (1, 20),\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'subsample': (0.5, 1.0),\n",
    "        'colsample_bytree': (0.5, 1.0)\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': (10, 200),\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lista de modelos para treinar com otimização bayesiana\n",
    "models = {\n",
    "    'DecisionTree': BayesSearchCV(DecisionTreeClassifier(random_state=42), param_grid['DecisionTree'], n_iter=32, cv=3, scoring='f1', random_state=42),\n",
    "    'RandomForest': BayesSearchCV(RandomForestClassifier(random_state=42), param_grid['RandomForest'], n_iter=32, cv=3, scoring='f1', random_state=42),\n",
    "    'XGBoost': BayesSearchCV(XGBClassifier(random_state=42), param_grid['XGBoost'], n_iter=32, cv=3, scoring='f1', random_state=42),\n",
    "    'AdaBoost': BayesSearchCV(AdaBoostClassifier(algorithm='SAMME', random_state=42), param_grid['AdaBoost'], n_iter=32, cv=3, scoring='f1', random_state=42)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar os melhores modelos e seus respectivos imbalance ratios\n",
    "best_models = {}\n",
    "\n",
    "for ratio in imbalance_ratios:\n",
    "    print(f\"Testing imbalance_ratio: {ratio}\")\n",
    "    \n",
    "    # Aplicar o RandomUnderSampler com o ratio atual\n",
    "    rus = RandomUnderSampler(sampling_strategy=ratio, random_state=42)\n",
    "    X_res, y_res = rus.fit_resample(X, y)\n",
    "    \n",
    "    # Inicializar a validação cruzada estratificada\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training model: {model_name}\")\n",
    "        \n",
    "        # Lista para armazenar os f1-scores de cada fold\n",
    "        fold_f1_scores = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(X_res, y_res):\n",
    "            X_train, X_test = X_res[train_index], X_res[test_index]\n",
    "            y_train, y_test = y_res[train_index], y_res[test_index]\n",
    "            \n",
    "            # Treinar o modelo\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Fazer previsões no conjunto de teste\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calcular o f1-score e armazenar na lista\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            fold_f1_scores.append(f1)\n",
    "        \n",
    "        # Calcular a média dos f1-scores dos folds e armazenar na lista principal\n",
    "        mean_f1 = np.mean(fold_f1_scores)\n",
    "        f1_scores.append(mean_f1)\n",
    "        \n",
    "        # Atualizar o dicionário de melhores modelos se o f1-score for o melhor até agora\n",
    "        if model_name not in best_models or mean_f1 > best_models[model_name]['f1_score']:\n",
    "            best_models[model_name] = {'model': model, 'imbalance_ratio': ratio, 'f1_score': mean_f1}\n",
    "\n",
    "# Encontrar o índice do melhor f1-score\n",
    "best_index = f1_scores.index(max(f1_scores))\n",
    "best_ratio = imbalance_ratios[best_index]\n",
    "\n",
    "print(f\"Melhor imbalance_ratio: {best_ratio} com F1-Score: {f1_scores[best_index]}\")\n",
    "print(\"Melhores modelos e seus respectivos imbalance ratios:\")\n",
    "print(best_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>0.948095</td>\n",
       "      <td>0.736664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.844284</td>\n",
       "      <td>0.772722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Modelo  \\\n",
       "DecisionTree            DecisionTreeClassifier(random_state=42)   \n",
       "RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "XGBoost       XGBClassifier(base_score=None, booster=None, c...   \n",
       "AdaBoost      (DecisionTreeClassifier(max_depth=1, random_st...   \n",
       "\n",
       "              Imbalance Ratio  F1-Score  \n",
       "DecisionTree         0.948095  0.736664  \n",
       "RandomForest         0.844284  0.772722  \n",
       "XGBoost              1.000000  0.758141  \n",
       "AdaBoost             1.000000  0.769796  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um DataFrame a partir do dicionário best_models\n",
    "df_best_models = pd.DataFrame.from_dict(best_models, orient='index')\n",
    "\n",
    "# Renomear as colunas para melhor entendimento\n",
    "df_best_models.columns = ['Modelo', 'Imbalance Ratio', 'F1-Score']\n",
    "\n",
    "# Exibir o DataFrame\n",
    "df_best_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
